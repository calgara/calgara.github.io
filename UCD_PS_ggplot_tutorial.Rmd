---
title: 'Programming & Methods Resources Workshop'
subtitle: "Introduction to The Grammar of Graphics (<tt>ggplot</tt>) & Data Visualization"
author: 
- "[Carlos Algara](mailto:calgara@ucdavis.edu), [Cory Struthers (Belden)](mailto:rbelden@ucdavis.edu), & [Jaime Jackson](mailto:jajack@ucdavis.edu)"
date: "5/25/2018"
output: html_document
---
<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-100362112-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-100362112-1');
</script>

<br/>

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
  
To replicate the following tutorial, you can find the replication code & data here: ***[R script](UCD_PS_ggplot_workshop_replication_code.R)*** &  ***[Tutorial Data in R Environment form](ggplot_tutorial.Rdata)***.
  
## *General Overview of <tt>ggplot</tt> Tutorial*

The basic logic (& relative advantages) behind the ggplot coding interface can be summarized in the following key points:

* Consistent langugage underlies the code, commonly referred to as the ``grammar of graphics'' (Wilkinson 2005)

* Very flexible programming which can, with few changes, be used to create multiple types of data visualization. For example, it takes one simple section of code to change a bar chart to a line graph.

* Many themes are available to polish and cutomize your high resolution plots.

* Most importantly, for our purposes, <tt>ggplot</tt> code is fully intergrated in the <tt>R</tt> computing environment. What this means is that we can derive multiple quantities of interest (descriptive statistics, model output, post-estimated model quantities of interest, etc.) using various packages and plot them using <tt>ggplot</tt>

* ***HUGE***, I'm talking HUGE, user community dedicated to providing crowd sourced code for whatever cutomization you seek in the <tt>ggplot</tt> environment.

In this tutorial, I will provide an applied tutorial to understanding the logic of the <tt>ggplot</tt> language while completing the following tasks:

1. Plotting descriptive distributions of key variables (histograms, density plots, bar charts, dot plots)

2. Plotting simple bivariate relationships of interest with appropriate measures of uncertainty around estimates (scatterplots, difference of means bar charts, boxplots)

3. Plotting model quantities of interests that provide for a graphical interpretation of our empirical work rather than tables. We will make coefficient plots articulating model output, plots articulating interactive relationships of interest, and post-estimation plots of interest (predicted probabilities from a logistic regerssion, marginal effects plots).

4. Basic preview to graphic add-ons to <tt>ggplot</tt> which provides for spatial mapping and plotting of social networks.
<br/>
<br/>

## *Plotting Descriptives*

For this example, let's tackle a problem plaguing the nature of ideological representation and congruence between the mass public and their elected elites (see [Achen's (1978)](http://www.jstor.org/stable/2110458?seq=1#page_scan_tab_contents) critique of the infamous [Miller & Stokes (1963)](http://www.jstor.org/stable/1952717?seq=1#page_scan_tab_contents) study as a primer on the methodological problem). Let's start by loading, exploring the data, and walking through some examples of plotting describtive data.

```{r echo=TRUE, message=F, warning=FALSE, r}
library(ggplot2) # Load ggplot2
library(plyr) # Loaad plyr, which provides tools for summarizing data
library(readstata13) # Load readstata13 to read Stata Files
library(dplyr) # Loaad dplyr, which provides tools that I always use, like as_tibble
library(reshape) # Load reshape, which provides for the melt function needed for data manipulation.

load("/Users/carlosalgara/Desktop/carlos_school/PhD_UC Davis/Dissertation Project/Ch2_Electoral_Implications_Approval/Aldrich_McKelvey_Scaling/Aldrich_McKelvey_Scaling_2008_2016_Positions_Results.Rdata") # Load R environment containing various estimations of candidate & citizen ideological ideal points from 2008-2016.

# Let's explore the nature of ideological preferences in the American electorate over time!

print(as_tibble(rescaled_overtime_idealpts_2008_2016))

# Huge data frame of scaled Aldrich-McKelvey ideal points for each CCES respondent from 2008-2016. For more information on the method deriving these scaled ideal points, see Ramey (2016).

# Of course, countless studies suggest that the distribution of ideological preferences of the mass public is unimodal. Let's make a density plot to see if this is the case.

ggplot(data=rescaled_overtime_idealpts_2008_2016,aes(x=idealpt))

# Not so fast my dude. We have to learn to crawl before we run, what happened?

# Now that we have some knowledge and have to specify our density plot aestic, let's get to work & make our plot!

ggplot(data=rescaled_overtime_idealpts_2008_2016,aes(x=idealpt)) + geom_density()

# Success! But there might be evidence that the distribution of ideological preferences might be trimodal. That is, clear partisan cleavages with respect to ideological preferences. Let's explore this possibility by first coding partisan preferences

rescaled_overtime_idealpts_2008_2016$pid3 <- ifelse(rescaled_overtime_idealpts_2008_2016$pid7 %in% c("Lean Republican","Not very strong Republican","Strong Republican"),"Republican",ifelse(rescaled_overtime_idealpts_2008_2016$pid7 %in% c("Lean Democrat","Not very strong Democrat","Strong Democrat"),"Democrat",ifelse(rescaled_overtime_idealpts_2008_2016$pid7 %in% c("Independent"),"Independent",NA)))

print(as_tibble(rescaled_overtime_idealpts_2008_2016)) # Let's check it out

ggplot(data=rescaled_overtime_idealpts_2008_2016,aes(x=idealpt,color=pid3)) + geom_density()

# Urgh, good start but pretty ugly and nowhere close to publication quality. Let's make this prettier by factoring out our pid3 and getting rid of "NA".

rescaled_overtime_idealpts_2008_2016$pid3 <- factor(rescaled_overtime_idealpts_2008_2016$pid3,levels=c("Democrat","Independent","Republican"))

print(str(rescaled_overtime_idealpts_2008_2016$pid3))

# Let's make a really pretty plot showing partisan differences.

ggplot(subset(rescaled_overtime_idealpts_2008_2016,rescaled_overtime_idealpts_2008_2016$pid3 != "Independent"),aes(x=idealpt,fill = pid3))+ geom_density(alpha=.2) + theme_bw() + scale_fill_manual("",values =c("blue","red")) + scale_x_continuous("Aldrich-McKelvey Ideological Placement (Liberal-Conservative)",breaks=c(-4,0,4),limits=c(-4,4),labels=c("-4","0","4")) + scale_y_continuous("Density",expand=c(0,0)) + theme(legend.position=c(0.10, 0.90), legend.box.just = "left", legend.key.size = unit(1,"line"), legend.key = element_rect(size = 0, color = 'white'), legend.text.align = 0, legend.box = "horizontal") + theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank())

# This is cool, let's do House candidates! First, let's check the data frame.

print(as_tibble(aldmck_congress))

# Oh no, we have to manipulate the dataframe. Urgh, bummer, but easy!

house_candidates <- subset(aldmck_congress,select=c("year","district","placement.dem_hse_libcon_placement","placement.rep_hse_libcon_placement")) # Extract the variables you want

house_candidates <- melt(house_candidates,id=c("year","district")) # Melt the dataframe from wide to long!

print(table(house_candidates$variable)) # We have one variable with a string variable indicating candidate type.

house_candidates$variable <- ifelse(house_candidates$variable == "placement.dem_hse_libcon_placement","Democrat",ifelse(house_candidates$variable == "placement.rep_hse_libcon_placement","Republican",NA))

ggplot(house_candidates, aes(x = value, fill = variable,linetype=variable)) + geom_density(alpha=.2) + theme_minimal() + scale_fill_manual("",values =c("blue","red")) + scale_x_continuous("Candidate Aldrich-McKelvey Ideological Placement (Liberal-Conservative)",limits=c(-1,1),breaks=c(-1,0,1),labels=c("-1","0","1")) + scale_y_continuous("Density",expand=c(0,0)) + theme(legend.position="bottom", legend.box.just = "left", legend.key.size = unit(1,"line"), legend.key = element_rect(size = 0, color = 'white'), legend.text.align = 0, legend.box = "horizontal") + scale_linetype_manual("",values=c("solid","dashed")) + facet_wrap(~year)

# What did we just do?

# We can also assess the validity of our ideal points by looking at the box plot distributions

ggplot(rescaled_overtime_idealpts_2008_2016, aes(x=selfplace, y=idealpts_linear_map_overtime, group=selfplace)) + geom_boxplot(colour = "black",outlier.shape = NA) + scale_y_continuous("Liberal-Conservative Aldrich-McKelvey Ideal Point Estimates",limits=c(-2.5,2.5),breaks=seq(-2,2,1)) + scale_x_continuous("Liberal-Conservative Raw Ideological Self-Placement",breaks=seq(1,7,1)) + scale_fill_discrete(guide=F) + stat_summary(fun.y = mean, geom="point",colour="black", size=2.00, shape= 17) + scale_shape_discrete("") + theme_minimal()
```

We can also plot descriptives, such as line graphs articulating trends in time. Let's load some data presidential approval from the great people at the [Roper Center](www.ropercenter.com) and also make a histogram for initial evaluation of our approval data.

```{r echo=T, message=F, warning=FALSE}
approval <- read.csv("/Users/carlosalgara/Desktop/carlos_school/PhD_UC Davis/Research/Data/American Politics/Presidential_Approval/presidents_survey_marginals_1969_2017.csv")

as_tibble(approval)

ggplot(approval, aes(x = approval_measure)) + geom_histogram(alpha=.2,fill="black",color="black") + theme_minimal() + scale_x_continuous("Presidential Approval Polling") + ggtitle("Distribution of Presidential Approval Polling Data, 1969-2017") 
```

Let's make a simple figure of presidential approval over time. Note, since we have data that is daily given the polling end date, we have to convert the date variable to something $\texttt{ggplot}$ can use.
```{r echo=T, message=F, warning=FALSE}
approval$Polling.End <- as.Date(approval$Polling.End)
ggplot(approval,aes(x=Polling.End,y=approval_measure)) + geom_line()
```

This is a really noisy plot, given the number of polls we have ($N$ = 4,075). Perhaps we are interested in a single president. $\texttt{ggplot}$ provides for flexibility in subsetting data for our purposes. Consider the following simple line graph looking at the history of presidential approval during the presidency of George W. Bush.

```{r echo=T, message=F, warning=FALSE}
ggplot(subset(approval,approval$president == "Bush"),aes(x=Polling.End,y=approval_measure)) + geom_line() + ggtitle("Presidential Approval during the George W. Bush Administration, 2001-2009")
```

Still a little noisy. What we could do is plot this using a series of boxplots by year to see how well George Bush's approval rating held up over the years.

```{r echo=T, message=F, warning=FALSE}
approval$year_factor <- factor(approval$year,levels=seq(1969,2017,1))
ggplot(subset(approval,approval$president == "Bush"),aes(x=year_factor,y=approval_measure)) + geom_boxplot() + ggtitle("Presidential Approval during the George W. Bush Administration, 2001-2009")
```

Why don't we take the mean for each year and fix our line graph? Let's add labels too to make the plot pretty and distinguish between Presidents.
```{r echo=T, message=F, warning=FALSE}
mean_approval <- ddply(approval, .(year), summarize,  approval_mean =mean(approval_measure, na.rm = T))

mean_approval$president <- ifelse(mean_approval$year %in% 1969, "Nixon",ifelse(mean_approval$year %in% 1974, "Ford",ifelse(mean_approval$year %in% 1977, "Carter",ifelse(mean_approval$year %in% 1981, "Reagan",ifelse(mean_approval$year %in% 1989, "Bush 43",ifelse(mean_approval$year %in% 1993, "Clinton",ifelse(mean_approval$year %in% 2001, "W. Bush",ifelse(mean_approval$year %in% 2009, "Obama",ifelse(mean_approval$year %in% 2017, "Trump",NA)))))))))

library(ggrepel) # Package the allows us to use label repels

ggplot(mean_approval,aes(x=year,y=approval_mean,label=president)) + geom_line() + theme_bw() + geom_label_repel(arrow = arrow(length = unit(0.02, 'npc')),segment.size = 0.5, box.padding = 0.5,point.padding = 1, size = 3.5) + ggtitle("Presidential Approval from Nixon to Trump, 1969-2017") + scale_x_continuous("",breaks=seq(1968,2016,4)) + scale_y_continuous("Yearly Presidential Approval Rating")
```


## *Plotting Bivariate Relationships*

While we implicitly plotted a bivariate relationship using the box-plot in the previous example, we can provide more explicit examples for studying bivariate relationships. Let's use data on the 2016 U.S. House elections to look at the relationship between presidential voteshare and House election voteshare. Also, let's fit a simple bivariate regression line to see in which districts Democratic candidates underperformed Clinton and which candidates over-performed Clinton. This will be articulated in the residual distance between the individual points and the point-estimate articulated in the regression line. In other words, the distance between the observed value $Y$ (in this case, the vote share won by the Democratic House candidate) and $\hat{Y}$ (in this case, the predicted vote share won by the Democratic House candidate articulated in the regression line).
```{r echo=F, message=F, warning=FALSE}
house <- read.dta13("/Users/carlosalgara/Desktop/carlos_school/PhD_UC Davis/Research/Data/American Politics/Carson_House_Elections/carson_jacobson_house_elex_1900_2016.dta")
house$dv[house$pwin == "Democratic Win" & is.na(house$dv)] <- 100 # Fix missing uncontested election data
house$dv[house$pwin == "Republican Win" & is.na(house$dv)] <- 0 # Fix missing uncontested election data
```

```{r echo=T, message=F, warning=FALSE}
as_tibble(house)
ggplot(subset(house,house$year %in% 2016),aes(x=dpres,y=dv)) + geom_point(shape=1) + geom_smooth(method='lm',SE=T,color="black") + theme_bw() + scale_x_continuous("District Two-Party Vote Share Won by the Democratic Presidential Candidate") + scale_y_continuous("District Two-Party Vote Share Won \nby the Democratic House Candidate") + ggtitle("Scatterplot of Democratic House Vote-Share by \nDemocratic Presidential Vote-Share in 2016")
```

Sometimes you want to add labels to the point scatters, so you can gain more information about outliers. Thus, let's recreate the scatter plot with district labels and colors for partisan control before the election.
```{r echo=T, message=F, warning=FALSE}
house$dem_seat <- ifelse(house$inc == "Dem Incum v. Dem Challenger",1,ifelse(house$inc == "Democratic Incumbent",1,ifelse(house$inc == "Democratic Open Seat",1,ifelse(house$inc == "Two Democrats, open seat",1,0))))
house$dem_seat <- factor(house$dem_seat,levels=c(0,1),labels=c("GOP Seat","Democratic Seat"))

house$district <- paste(house$state,house$cd,sep="")

ggplot(subset(house,house$year %in% 2016),aes(x=dpres,y=dv,color=dem_seat,label=district)) + geom_text(size=2) + geom_smooth(method='lm',SE=T,color="black") + theme_bw() + scale_color_manual("Seat Partisanship",values=c("red","blue")) + scale_x_continuous("District Two-Party Vote Share Won by the Democratic Presidential Candidate",breaks=seq(0,100,10)) + scale_y_continuous("District Two-Party Vote Share Won \nby the Democratic House Candidate",breaks=seq(0,100,10)) + ggtitle("Scatterplot of Democratic House Vote-Share by \nDemocratic Presidential Vote-Share")  + geom_hline(yintercept = 50, colour = gray(1/2), lty = 2) + theme(legend.position="bottom")
```

What if I was interested in looking at multiple election cycles of interest? Looks look at the pivotal elections of 1974, 1994, 2006, and 2010. Let's take a look!
```{r echo=T, message=F, warning=FALSE}
ggplot(subset(house,house$year %in% c(1974, 1994,2006,2010)),aes(x=dpres,y=dv,color=dem_seat,label=district)) + geom_point(shape=1) + geom_smooth(method='lm',SE=T,color="black") + theme_minimal() + scale_color_manual("Seat Partisanship",values=c("red","blue")) + scale_x_continuous("District Two-Party Vote Share Won by the Democratic Presidential Candidate",breaks=seq(0,100,10)) + scale_y_continuous("District Two-Party Vote Share Won \nby the Democratic House Candidate",breaks=seq(0,100,25)) + ggtitle("Scatterplot of Democratic House Vote-Share by \nDemocratic Presidential Vote-Share")  + geom_hline(yintercept = 50, colour = gray(1/2), lty = 2) + theme(legend.position="bottom") + facet_wrap(~year,ncol=2) + theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), panel.background = element_blank()) # The last part of the code takes out all gridlines.
```

In the next section, we will explore how to articulate the results of a simple analysis of variance. For this, we will evaluate the nature of differential item functioning (DIF) in citizen perceptions of political candidates and parties. The problem of DIF can be illustrated in the following example in which the ideological placement of the Democratic party might vary by the ideological perception of a survey respondent. For example, a conserative respondent may place the Democrats on the far-left of the scale (at a 1 on the standard liberal-conservative 7 point scale) while a liberal respondent may place the Democrats more towards the center of the scale (at a 3 or so on the standard liberal-conservative scale). While methods, such as Aldrich-McKelvey scaling, corrects for this measurement error and estimates ``true'' ideological positions of political stimului (see [Hare et al. 2016](https://onlinelibrary.wiley.com/doi/abs/10.1111/ajps.12151) for further details on this estimation), it is important to empirically atriculate the problem.  
  
For this, we turn to the 2016 [Cooperative Congressional Election Study](https://cces.gov.harvard.edu) to see if DIF manifests itself in the mass public.

```{r echo=T, message=F, warning=FALSE}
cces <- read.dta13("/Users/carlosalgara/Dropbox/CCES2016_UCD_original/common/CCES2016.dta",convert.factors = F)
cces <- subset(cces,select=c("CC16_340a","CC16_340d","CC16_340e"))
colnames(cces) <- c("self_placement","hrc_placement","dt_placement")

as_tibble(cces)

cces[cces == 8] <- NA # Recode 8, the missing code, to missing
cces <- na.omit(cces)

sample_means <- ddply(cces, .(self_placement), summarize, hrc_sd = sd(hrc_placement,na.rm=T), dt_sd = sd(dt_placement,na.rm=T),hrc_placement = mean(hrc_placement, na.rm = T), dt_placement = mean(dt_placement, na.rm = T))

z_critical_value <- qnorm(0.975)

x <- data.frame(table(cces$self_placement)) # Retrieve Ns

sample_means$self_placement_n <- x[,2]

sample_means$margin_of_error_hrc <- z_critical_value * (sample_means$hrc_sd / sqrt(sample_means$self_placement_n)) # Get margin of error for HRC

sample_means$margin_of_error_dt <- z_critical_value * (sample_means$dt_sd / sqrt(sample_means$self_placement_n)) # Get margin of error for DT

sample_means$hrc_lower_ci <- sample_means$hrc_placement - sample_means$margin_of_error_hrc
sample_means$hrc_upper_ci <- sample_means$hrc_placement + sample_means$margin_of_error_hrc

sample_means$dt_lower_ci <- sample_means$dt_placement - sample_means$margin_of_error_dt
sample_means$dt_upper_ci <- sample_means$dt_placement + sample_means$margin_of_error_dt

# Let's rework our dataframe to get Trump and Clinton on the same plot

colnames(sample_means)

hrc <- sample_means[,c(1,4,9,10)]
dt <- sample_means[,c(1,5,11,12)]

colnames(hrc) <- c("self_placement","mean","lower","upper")
colnames(dt) <- c("self_placement","mean","lower","upper")

hrc$candidate <- "Hillary Clinton"
dt$candidate <- "Donald Trump"

sample_means <- rbind(hrc,dt)

ggplot(sample_means,aes(x=self_placement,y=mean,ymin=lower,ymax=upper,color=candidate)) + geom_pointrange() + scale_color_manual("2016 Presidential Candidate",values=c("red","blue")) +  theme_minimal() + scale_x_continuous("Respondent Liberal-Conservative Self-Placement",breaks=seq(1,7,1)) + scale_y_continuous("Mean Ideological Placement of Hillary Clinton") + ggtitle("Evaluating Differential Item Function in Citizen Ideological Placement \nof the 2016 Presidential Candidates") + theme(legend.position="bottom")
```

It's hard to see the confidence intervals! Let's do the candidates on by one to see the DIF up-close.

```{r echo=T, message=F, warning=FALSE}
ggplot(subset(sample_means,sample_means$candidate == "Hillary Clinton"),aes(x=self_placement,y=mean,ymin=lower,ymax=upper)) + geom_pointrange() +  theme_minimal() + scale_x_continuous("Respondent Liberal-Conservative Self-Placement",breaks=seq(1,7,1)) + scale_y_continuous("Mean Ideological Placement of Hillary Clinton") + ggtitle("Evaluating Differential Item Function in Citizen Ideological Placement \nof Hillary Clinton, 2016 CCES")

ggplot(subset(sample_means,sample_means$candidate == "Donald Trump"),aes(x=self_placement,y=mean,ymin=lower,ymax=upper)) + geom_pointrange() +  theme_minimal() + scale_x_continuous("Respondent Liberal-Conservative Self-Placement",breaks=seq(1,7,1)) + scale_y_continuous("Mean Ideological Placement of Donald Trump") + ggtitle("Evaluating Differential Item Function in Citizen Ideological Placement \nof Donald Trump, 2016 CCES")
```

Strong evidence for differential item functioning across respondent liberal-conservative self-placement! This would necessitate the need for method of correctinf for this distortion in left-right scale perceptions.

## *Plotting Model Quantities of Interest*

In this section, we turn to post-estimating model quantitites of interest. First, let's explore estimating average marginal effects from a simple regression model. We return to our House dataset and specify a pooled vote-share model of House elections from 1900-2016.

```{r echo=F, message=F, warning=FALSE}
house$seat_partisanship <- ifelse(house$inc == "GOP Incumbent", "Republican", ifelse(house$inc == "Democratic Incumbent", "Democratic", ifelse(house$inc == "Democratic Open seat", "Democratic", ifelse(house$inc == "GOP Open Seat", "Republican", NA))))
house$dem_incumbency <- ifelse(house$inc == "Democratic Incumbent", 1, ifelse(house$inc == "GOP Incumbent", -1, 0))
house$dem_seat <- ifelse(house$seat_partisanship == "Republican", 0, ifelse(house$seat_partisanship == "Democratic", 1, NA))
house$incumbent_reelex <- ifelse(house$inc == "Democratic Incumbent", 1, ifelse(house$inc == "Dem Open Seat", 0, ifelse(house$inc == "GOP Incumbent", 1, ifelse(house$inc == "GOP Open Seat", 0, ifelse(house$inc == "New Open Seat (reapportioned)", 0, NA)))))

house$dem_qual_advantage_tri <- ifelse(house$seat_partisanship == "Democratic" & house$incumbent_reelex == 1 & house$po1 == "Amateur Challenger", 1, ifelse(house$seat_partisanship == "Republican" & house$incumbent_reelex == 1 & house$po1 == "Amateur Challenger", -1, ifelse(house$seat_partisanship == "Democratic" & house$incumbent_reelex == 1 & house$po1 == "Quality Challenger", 0, ifelse(house$seat_partisanship == "Republican" & house$incumbent_reelex == 1 & house$po1 == "Quality Challenger", 0, ifelse(house$seat_partisanship == "Democratic" & house$incumbent_reelex == 0 & house$po1 == "Amateur Challenger", 1, ifelse(house$seat_partisanship == "Republican" & house$incumbent_reelex == 0 & house$po1 == "Amateur Challenger", -1, ifelse(house$seat_partisanship == "Democratic" & house$incumbent_reelex == 0 & house$po1 == "Quality Challenger", 0, ifelse(house$seat_partisanship == "Republican" & house$incumbent_reelex == 0 & house$po1 == "Quality Challenger", 0, ifelse(house$seat_partisanship == "Democratic" & house$incumbent_reelex == 0 & house$po1 == "Only Democratic Quality Candidate (open)", 1, ifelse(house$seat_partisanship == "Republican" & house$incumbent_reelex == 0 & house$po1 == "Only Democratic Quality Candidate (open)", 1, ifelse(house$seat_partisanship == "Democratic" & house$incumbent_reelex == 0 & house$po1 == "Only GOP Quality Candidate (open)", -1, ifelse(house$seat_partisanship == "Republican" & house$incumbent_reelex == 0 & house$po1 == "Only GOP Quality Candidate (open)", -1, ifelse(house$po1 == "Both Quality Candidates (open)", 0, NA)))))))))))))  
house$dv[house$dv == 0] <- NA
house$dv[house$dv == 100] <- NA
house_elexs <- house[,c(1,17,7,15,16,19,21,8)]
house_elexs$dvp[is.na(house_elexs$dvp) & house_elexs$dem_seat == 1] <- 100
house_elexs$dvp[is.na(house_elexs$dvp) & house_elexs$dem_seat == 0] <- 0
```

```{r echo=T, message=F, warning=FALSE}
as_tibble(house_elexs)

library(margins) # Load Thomas Leeper's Margins Package

summary(model <- glm(dv ~ dem_incumbency + dpres + dem_qual_advantage_tri + dem_seat + dvp, data=house_elexs)) # Estimate our pooled model

mes <- data.frame(summary(margins(model, change="dydx", vcov.=vcovHC(model, "HC3"))))
```

Leeper's ["margins"](https://github.com/leeper/margins) command allows us to look at the average marginal effect of our covariates, in this case incumbency ($\texttt{dem_incumbency}$), district partisanship ($\texttt{dpres}$), candidate quality (($\texttt{dem_qual_advantage_tri}$)), seat partisanship ($\texttt{dem_seat}$), and previous district election vote share ($\texttt{dem_seat}$). Let's use $\texttt{ggplot}$ to create a nice coefficient plot articulating average marginal effects of our key variables.

```{r echo=T, message=F, warning=FALSE}
head(mes)

mes$factor <- ifelse(mes$factor == "dem_incumbency","Incumbency",ifelse(mes$factor == "dem_qual_advantage_tri","Candidate Quality",ifelse(mes$factor == "dem_seat","Seat Partisanship",ifelse(mes$factor == "dpres","District Partisanship",ifelse(mes$factor == "dvp","Previous District Dem Vote-Share",NA)))))

mes$factor <- factor(mes$factor)

ggplot(mes,aes(x=factor,y=AME,ymin=lower,ymax=upper,group=factor,shape=factor)) + theme_minimal() + geom_errorbar(width=0.2,size=1) + geom_point(size=3, fill="white",position= position_dodge(width=1.0)) + scale_x_discrete("") + scale_shape_manual("",values=c(21,21,21,21,21)) + theme(legend.position="none") + coord_flip() + geom_hline(yintercept = 0, colour = gray(1/2), lty = 2) + scale_y_continuous("Average Marginal Effect") + ggtitle("Average Marginal Effect of Model Covarates on House Election Vote Shares")
```

Of course, election dynamics have changed over time and it may be inapproriate to specify a pooled model. Some work argues that the effect of incumbency and state partisanship, in particular, on House election outcomes have varied as elections move from candidate-centered to partisan-centered contexts. Let's estimate our model yearly to explore these two specific dynamics, incumbency and state partisanship, and how they vary over time.

```{r echo=T, message=F, warning=FALSE}
mes_yearly <- list()
for(i in seq(1900,2016,2)){
  x <- subset(house,house$year == i)
model <- glm(dv ~ dem_incumbency + dpres + dem_qual_advantage_tri + dem_seat + dvp, data=x) # Estimate our yearly model
mes <- data.frame(summary(margins(model, change="dydx", vcov.=vcovHC(x, "HC3"))))
mes$election_year <- i
mes_yearly[[i]] <- mes
}

mes_yearly <- ldply(mes_yearly,data.frame) # Unpack the list

head(mes_yearly)

mes_yearly$factor <- ifelse(mes_yearly$factor == "dem_incumbency", "Incumbency Advantage",ifelse(mes_yearly$factor == "dpres", "District Partisanship",mes_yearly$factor))

ggplot(subset(mes_yearly,mes_yearly$factor %in% c("Incumbency Advantage")),aes(x=election_year,y=AME,ymin=lower,ymax=upper)) + geom_pointrange() + theme_minimal() + ggtitle("Effect of Incumbency on House Election Outcomes from 1900-2016") + scale_x_continuous("",breaks=seq(1900,2016,10)) + geom_smooth(method="loess") + geom_hline(yintercept = 0, colour = gray(1/2), lty = 2)

ggplot(subset(mes_yearly,mes_yearly$factor %in% c("District Partisanship")),aes(x=election_year,y=AME,ymin=lower,ymax=upper)) + geom_pointrange() + theme_minimal() + ggtitle("Effect of District Partisanship on House Election Outcomes from 1900-2016") + scale_x_continuous("",breaks=seq(1900,2016,10)) + geom_smooth(method="loess") + geom_hline(yintercept = 0, colour = gray(1/2), lty = 2)
```

Now let's turn to logits! Let's extract some predicted probabilities! For this example, we turn to investigating the relationship between income, education, and the probability of turning out to vote using data from the 2014 Cooperative Congressional Election Study.

```{r echo=F, message=F, warning=FALSE}
cces <- read.dta13(paste("/Users/carlosalgara/Desktop/carlos_school/PhD_UC Davis/Research/Data/American Politics/CCES/CCES",2014,".dta",sep=""),convert.factors = T, convert.underscore = FALSE, encoding ="UTF-8")

resources <- subset(cces,select=c(weight,cdid,CC401,CC417a_4,faminc,educ))
resources[] <- lapply(resources, as.character)
colnames(resources) <- c("weight","cdid","turnout","contribute","income","education")

resources$turnout[resources$turnout == "I did not vote in the election this November."] <- 0
resources$turnout[resources$turnout == "I thought about voting this time â€“ but didn't."] <- 0
resources$turnout[resources$turnout == "I usually vote, but didn't this time."] <- 0
resources$turnout[resources$turnout == "I attempted to vote but did not or could not."] <- 0
resources$turnout[resources$turnout == "I definitely voted in the Midterm Election on November 4th."] <- 1

resources$contribute[resources$contribute == "No"] <- 0
resources$contribute[resources$contribute == "Yes"] <- 1

library(descr)
na <- data.frame(freq(resources$income,plot=F))
na$category <- rownames(na)
rownames(na) <- NULL

resources$income[resources$income %in% as.character(na[18,4])] <- 0
resources$income[resources$income %in% as.character(na[1,4])] <- 1
resources$income[resources$income %in% as.character(na[6,4])] <- 2
resources$income[resources$income %in% as.character(na[10,4])] <- 3
resources$income[resources$income %in% as.character(na[12,4])] <- 4
resources$income[resources$income %in% as.character(na[13,4])] <- 5
resources$income[resources$income %in% as.character(na[15,4])] <- 6
resources$income[resources$income %in% as.character(na[16,4])] <- 7
resources$income[resources$income %in% as.character(na[17,4])] <- 8
resources$income[resources$income %in% as.character(na[2,4])] <- 9
resources$income[resources$income %in% as.character(na[3,4])] <- 10
resources$income[resources$income %in% as.character(na[4,4])] <- 11
resources$income[resources$income %in% as.character(na[7,4])] <- 12
resources$income[resources$income %in% as.character(na[8,4])] <- 13
resources$income[resources$income %in% as.character(na[11,4])] <- 14
resources$income[resources$income %in% as.character(na[14,4])] <- 15
resources$income[resources$income %in% as.character(na[9,4])] <- 13
resources$income[resources$income %in% as.character(na[5,4])] <- 11
resources$income[resources$income %in% as.character(na[c(19,20),4])] <- NA

resources$education <- factor(resources$education,levels=c("No HS","High school graduate","Some college","2-year","4-year","Post-grad"))

resources$income <- as.numeric(resources$income)
resources$weight <- as.numeric(resources$weight)
resources$turnout <- as.numeric(resources$turnout)
resources$contribute <- as.numeric(resources$contribute)

library(effects)
library(sandwich)
library(lmtest)
library(multiwayvcov)
```

```{r echo=T, message=F, warning=FALSE}
as_tibble(resources)

# Turnout ~ Education

model <- glm(turnout ~ education, data=resources, weights=weight, family = binomial(link = "logit"))
predict <- data.frame(effect("education", se=TRUE, mod = model, confidence.level = 0.95, xlevels=list(vcov. = cluster.vcov(model, cluster=resources$cdid))))

predict$education <- factor(predict$education,levels=c("No HS","High school graduate","Some college","2-year","4-year","Post-grad"))

ggplot(data= predict, mapping=aes(x=education, y=fit, ymin=lower, ymax=upper, fill=education)) + geom_bar(stat="identity") + geom_errorbar(width=.25) + theme_bw() + theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank()) + scale_x_discrete("Voter Education Level") + scale_y_continuous(limits=c(0,1.0), breaks=seq(0,1.0,0.05), "Probability of Turning Out to Vote") + ggtitle("Probability of Voter Turnout by Education Level in the 2014 Midterm Elections") + coord_cartesian(ylim=c(0.70,1.0)) + scale_fill_discrete(guide=FALSE)

# Turnout ~ Income

model <- glm(turnout ~ income, data=resources, weights=weight, family = binomial(link = "logit"))
predict <- data.frame(effect("income", se=TRUE, mod = model, confidence.level = 0.95, xlevels=list(income = seq(0,15,1), (vcov. = cluster.vcov(model, cluster=resources$cdid)))))

ggplot(data= predict, mapping=aes(x=income, y=fit)) + geom_line(aes(x = income, y = fit), size = 0.50) + geom_ribbon(aes(ymin=lower, ymax=upper), alpha = .2) + scale_colour_manual("",values="black") + scale_fill_manual("",values="grey12") + theme_bw() + theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank()) + scale_x_continuous(limits=c(0,15), breaks=c(0,15), labels=c("Less than \n$10,000", "Greater than \n$500,000"), "Voter Income") + scale_y_continuous(limits=c(0.7,1.0), breaks=seq(0.7,1.0,0.05), "Probability of Turning Out to Vote") + ggtitle("Probability of Voter Turnout by Income Level in the 2014 Midterm Elections")
```

What if we want to specify a logistic regression model positing that the effect of education on turning out to vote is conditioned by income? Let's explore that in the following code.

```{r echo=T, message=F, warning=FALSE}
resources$education <- factor(resources$education,levels=c("No HS","High school graduate","Some college","2-year","4-year","Post-grad"))

model <- glm(turnout ~ education*income, data=resources, weights=weight, family = binomial(link = "logit"))
predict <- data.frame(effect("education*income", se=TRUE, mod = model, confidence.level = 0.95, xlevels=list(income=unique(resources$income),vcov. = cluster.vcov(model, cluster=resources$cdid))))
head(predict)
predict$education <- factor(predict$education,levels=c("No HS","High school graduate","Some college","2-year","4-year","Post-grad"))

ggplot(predict, aes(x=income, y=fit, group=education,fill=education,linetype=education)) + geom_line(aes(x = income, y = fit), size = 0.50) + geom_ribbon(aes(ymin=lower, ymax=upper), alpha = .2) + theme_bw() + theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank()) + scale_x_continuous(limits=c(0,15), breaks=c(0,15), labels=c("Less than \n$10,000", "Greater than \n$500,000"), "Voter Income") + scale_y_continuous(limits=c(0.5,1.0), breaks=seq(0.5,1.0,0.05), "Probability of Turning Out to Vote") + ggtitle("Probability of Voter Turnout by Income & Education Level in the 2014 \nMidterm Elections") + theme(legend.position="bottom", legend.box.just = "left", legend.key.size = unit(1,"line"), legend.key = element_rect(size = 0, color = 'white'), legend.text.align = 0, legend.box = "horizontal") + scale_fill_discrete("") + scale_linetype_discrete("")
```

Among those with no HS diploma, income has a pronounced positive effect on the probability of turning out to vote. For the other education categories, not so much, especially among those with a post-grad. We can also use the code to estimate predicted probabilities for models with categorical dependent variables. Let's explore this by specifying a multinomial logistic regression evaluating the effect of social network poltiical disagreement on a citizen's approval evaluation of President Barack Obama in 2016. For this analysis, we will use data from the 2016 UCD & UGA modeul.

```{r echo=F, message=F, warning=FALSE}
cces <- read.dta13("/Users/carlosalgara/Dropbox/CCES2016_UCD_original/CCES16_UCDUGA_combined.dta",convert.factors = T, convert.underscore = FALSE, encoding ="UTF-8")
cces_variables <- read.csv("/Users/carlosalgara/Desktop/carlos_school/PhD_UC Davis/Research/Twitter/Butters_NetworkDisagreement.csv",stringsAsFactors = F)

# Subset the data based on the specified variables in the spreadsheet

cces_variables <- cces_variables[,colSums(is.na(cces_variables))<nrow(cces_variables)]
cces_variables <- cces_variables[,-c(1)]
cces_vars_cols <- colnames(cces_variables)
cces_vars <- as.character(cces_variables[1,])
names.use <- names(cces)[(names(cces) %in% cces_vars)]
cces <- cces[, cces_vars]
colnames(cces) <- cces_vars_cols
cces %>% mutate_if(is.factor, as.character) -> cces  #Convert factors to characters
cces %>% mutate_if(is.numeric, as.character) -> cces  #Convert numeric to characters

### Code Variables

###################

# Party ID.
cces$pid7_clean <- cces$pid7

na <- data.frame(freq(cces$pid7_clean,plot=F))
na$values <- rownames(na)
rownames(na) <- NULL
cces$pid7_clean[cces$pid7_clean %in% as.character(na[1,4])] <- "Independent"
cces$pid7_clean[cces$pid7_clean %in% as.character(na[2,4])] <- "Lean Democrat"
cces$pid7_clean[cces$pid7_clean %in% as.character(na[3,4])] <- "Lean Republican"
cces$pid7_clean[cces$pid7_clean %in% as.character(na[4,4])] <- NA
cces$pid7_clean[cces$pid7_clean %in% as.character(na[5,4])] <- "Weak Democrat"
cces$pid7_clean[cces$pid7_clean %in% as.character(na[6,4])] <- "Weak Republican"
cces$pid7_clean[cces$pid7_clean %in% as.character(na[7,4])] <- "Strong Democrat"
cces$pid7_clean[cces$pid7_clean %in% as.character(na[8,4])] <- "Strong Republican"

###################

# Presidential Approval

cces$pres_approve_clean <- cces$pres_approve

na <- data.frame(freq(cces$pres_approve_clean,plot=F))
na$values <- rownames(na)
rownames(na) <- NULL
cces$pres_approve_clean[cces$pres_approve_clean %in% as.character(na[1,3])] <- NA

###################

# Partisanship Recode

cces$pid3_clean <- ifelse(cces$pid7_clean == "Lean Democrat","Democrat", ifelse(cces$pid7_clean == "Weak Democrat", "Democrat", ifelse(cces$pid7_clean == "Strong Democrat", "Democrat", ifelse(cces$pid7_clean == "Lean Republican","Republican", ifelse(cces$pid7_clean == "Weak Republican", "Republican", ifelse(cces$pid7_clean == "Strong Republican", "Republican", ifelse(cces$pid7_clean == "Independent","Independent", NA)))))))

# Network Party 1

cces$network_party1_clean <- cces$network_party1

na <- data.frame(freq(cces$network_party1_clean,plot=F))
na$values <- rownames(na)
rownames(na) <- NULL
cces$network_party1_clean[cces$network_party1_clean %in% as.character(na[1,4])] <- "Bipartisan"
cces$network_party1_clean[cces$network_party1_clean %in% as.character(na[2,4])] <- "Democrats"
cces$network_party1_clean[cces$network_party1_clean %in% as.character(na[3,4])] <- NA
cces$network_party1_clean[cces$network_party1_clean %in% as.character(na[4,4])] <- NA
cces$network_party1_clean[cces$network_party1_clean %in% as.character(na[5,4])] <- "Republicans"

cces$network_party2_clean <- cces$network_party2

na <- data.frame(freq(cces$network_party2_clean,plot=F))
na$values <- rownames(na)
rownames(na) <- NULL
cces$network_party2_clean[cces$network_party2_clean %in% as.character(na[1,4])] <- "Bipartisan"
cces$network_party2_clean[cces$network_party2_clean %in% as.character(na[2,4])] <- "Democrats"
cces$network_party2_clean[cces$network_party2_clean %in% as.character(na[3,4])] <- NA
cces$network_party2_clean[cces$network_party2_clean %in% as.character(na[4,4])] <- NA
cces$network_party2_clean[cces$network_party2_clean %in% as.character(na[5,4])] <- "Republicans"

cces$network_party3_clean <- cces$network_party3

na <- data.frame(freq(cces$network_party3_clean,plot=F))
na$values <- rownames(na)
rownames(na) <- NULL
cces$network_party3_clean[cces$network_party3_clean %in% as.character(na[1,4])] <- "Bipartisan"
cces$network_party3_clean[cces$network_party3_clean %in% as.character(na[2,4])] <- "Democrats"
cces$network_party3_clean[cces$network_party3_clean %in% as.character(na[3,4])] <- NA
cces$network_party3_clean[cces$network_party3_clean %in% as.character(na[4,4])] <- NA
cces$network_party3_clean[cces$network_party3_clean %in% as.character(na[5,4])] <- "Republicans"

# Network Heterogenity

cces$network_party1_dem <- ifelse(cces$network_party1_clean == "Democrats", 1, ifelse(cces$network_party1_clean == "Republicans", -1, ifelse(cces$network_party1_clean == "Bipartisan", 0, NA)))
cces$network_party2_dem <- ifelse(cces$network_party2_clean == "Democrats", 1, ifelse(cces$network_party2_clean == "Republicans", -1, ifelse(cces$network_party2_clean == "Bipartisan", 0, NA)))
cces$network_party3_dem <- ifelse(cces$network_party3_clean == "Democrats", 1, ifelse(cces$network_party3_clean == "Republicans", -1, ifelse(cces$network_party3_clean == "Bipartisan", 0, NA)))

# Create Respondent ID

library(data.table)
cces <- data.table(cces)
cces <- cces[, respondent_id := 1:.N]

network <- cces[,35:38]
rownames(network) <- network$respondent_id
network$respondent_id <- NULL
network$hetero <- rowMeans(network,na.rm=T)
network$hetero_notmissing <- rowMeans(network[,1:3],na.rm=F)
network$hetero[network$hetero == "NaN"] <- NA
network$respondent_id <- rownames(network)
network <- network[,4:6]
network$respondent_id <- as.numeric(network$respondent_id)

cces <- merge(cces,network,by=c("respondent_id"),all=T)

cces$dem_pid3 <- ifelse(cces$pid3_clean == "Democrat",1, ifelse(cces$pid3_clean == "Independent", 0, ifelse(cces$pid3_clean == "Republican", -1, NA)))

cces$pres_approve_dich <- ifelse(cces$pres_approve_clean == "Somewhat approve", 1, ifelse(cces$pres_approve_clean == "Strongly approve", 1, ifelse(cces$pres_approve_clean == "Somewhat disapprove", 0, ifelse(cces$pres_approve_clean == "Strongly disapprove", 0, NA))))

cces$weight <- as.numeric(cces$weight)

cces$pres_approve_clean_factor <- factor(cces$pres_approve_clean,levels=c("Strongly disapprove","Somewhat disapprove","Somewhat approve","Strongly approve"))

library(mlogit)
library(mnlogit)
library(clusterSEs)
#cluster.bs.mlogit(model,data,~chid,ci.level=0.95,cluster.se=F)
cces$constant <- 1
```

```{r echo=T, message=F, warning=FALSE}
library(nnet)
summary(model <- multinom(pres_approve_clean_factor ~ dem_pid3 + hetero, data=cces, weights=weight, hess=T))

predict <- effect("hetero", se=TRUE, mod = model, confidence.level = 0.95, xlevels=list(hetero=c(-1,-0.6666667,-0.5000000,-0.3333333,0.0000000,0.3333333,0.5000000,0.6666667,1.0000000)))
predict <- data.frame(predict)

# Reshape Probabilities

fit <- predict[,1:5]
lower <- predict[,c(1,18:21)]
upper <- predict[,c(1,22:25)]

colnames(fit) <- c("hetero","fit.Strongly Disapprove","fit.Somewhat Disapprove","fit.Somewhat Approve","fit.Strongly Approve")
fit <- reshape(fit,idvar="hetero",varying=c("fit.Strongly Disapprove","fit.Somewhat Disapprove","fit.Somewhat Approve","fit.Strongly Approve"),se=".",timevar="approval",times=c("Strongly Disapprove","Somewhat Disapprove","Somewhat Approve","Strongly Approve"),direction="long")

colnames(lower) <- c("hetero","lower.Strongly Disapprove","lower.Somewhat Disapprove","lower.Somewhat Approve","lower.Strongly Approve")
lower <- reshape(lower,idvar="hetero",varying=c("lower.Strongly Disapprove","lower.Somewhat Disapprove","lower.Somewhat Approve","lower.Strongly Approve"),se=".",timevar="approval",times=c("Strongly Disapprove","Somewhat Disapprove","Somewhat Approve","Strongly Approve"),direction="long")

colnames(upper) <- c("hetero","upper.Strongly Disapprove","upper.Somewhat Disapprove","upper.Somewhat Approve","upper.Strongly Approve")
upper <- reshape(upper,idvar="hetero",varying=c("upper.Strongly Disapprove","upper.Somewhat Disapprove","upper.Somewhat Approve","upper.Strongly Approve"),se=".",timevar="approval",times=c("Strongly Disapprove","Somewhat Disapprove","Somewhat Approve","Strongly Approve"),direction="long")

predict <- merge(fit,upper,by=c("hetero","approval"))
predict <- merge(predict,lower,by=c("hetero","approval"))

predict$approval <- factor(predict$approval,levels=c("Strongly Disapprove","Somewhat Disapprove","Somewhat Approve","Strongly Approve"))

ggplot(data= predict, mapping=aes(x=hetero, y=fit)) + geom_line(aes(x = hetero, y = fit), size = 0.50) + geom_ribbon(aes(ymin=lower, ymax=upper), alpha = .2) + scale_colour_manual("",values="black") + scale_fill_manual("",values="grey12") + theme_bw() + theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank()) + scale_x_continuous(limits=c(-1,1), breaks=c(-1,0,1), labels=c("GOP", "Neutral","Dem"), "Partisan Network Homogenity") + scale_y_continuous(limits=c(0,0.70), breaks=seq(0,0.70,0.10), "Predicted Probability of Presidential Approval") + geom_rug(data=cces, aes(x=hetero, y=1),color = "gray30", alpha=.5, size = 0.25, position='jitter') + ggtitle("Probability of Approving of President Obama by Partisan Network Homogenity") + facet_wrap(~approval, ncol = 2, scales = "free_y") 
```

The results of the multinomial logit model are stirking. After accounting for a respondent's partisanship, being in a social network full of Democrats lowers the probability of disapproving of Obama relative to all other categories of approval. Moreover, being in a political social network full of Democrats increases the probability of approval relative to all other categories of approval. This is one way in which you can specify a multinomial logit, extract the estimates, and use $\texttt{ggplot}$ to articulate the results.

## *Short Introduction into ggplot add-ons for plotting Maps & Networks*

We can also use $\texttt{ggplot}$ to make nice maps and convey the structure of social networks. Let's start with making a map of 2016 presidential approval by state. These data are dynamic MRP estimates derived from the 2016 CCES sample. For more information on how to estimate group-level political attitudes using dynamic MRP model estimation, see [Caughey & Warshaw 2015](http://caughey.mit.edu/sites/default/files/documents/CaugheyWarshaw_DIRT140803.pdf).
  
For this exercise, we need to load a shapefile into R.
```{r echo=T, message=F, warning=FALSE}
# Load the shapefile that has the data to plot maps in ggplot!
# Let's play around with mapping

# Load the shapefile that has the data to plot maps in ggplot!

library(rgdal)

state_shp <- readOGR("/Users/carlosalgara/Desktop/carlos_school/PhD_UC Davis/Research/Data/American Politics/US House_District_Shape_Files/cb_2016_us_state_20m.shp")

# Let's explore the data embedded in the shape file

as_tibble(state_shp@data) # Dataframe embedded in the Spatial Polygons Data Frame

as_tibble(state_shp@data$NAME) # What type of states are in the file? We don't want territories!

state_shp <- subset(state_shp,state_shp@data$NAME != "Puerto Rico")
state_shp <- subset(state_shp,state_shp@data$NAME != "Alaska")
state_shp <- subset(state_shp,state_shp@data$NAME != "Hawaii")
state_shp <- subset(state_shp,state_shp@data$NAME != "District of Columbia")

# Preliminary look at our map

ggplot(state_shp, aes(x = long, y = lat, group = group)) + geom_polygon(fill = "gray", color = "black") + theme_void() + coord_equal() + coord_fixed(1.3)
```

Now that we have successfully loaded our shapefile containing our mapping data into R, let's merge some state  presidential approval data and make a map showing the spatial variation in approval for President Barack Obama in 2016.

```{r echo=T, message=F, warning=FALSE}
state_pres_approval <- read.dta13("/Users/carlosalgara/Desktop/carlos_school/PhD_UC Davis/Dissertation Project/Ch2_Electoral_Implications_Approval/MRP_Estimation/state_presidential_approval_dynamic_mrp_estimates.dta") # Load the data

as_tibble(state_pres_approval) # Get a glimpse of the data structure. These are Dynamic MRP state-level estimates (see: Caughey & Warshaw (2015) for technical details on the Dynamic MRP model) of presidential approval from 2008-2017. 

# Explore map making descriptives. Let's make a plot of presidential approval for December 2017.

# Make a percentage

state_pres_approval$state_pres_approval_percent <- state_pres_approval$median * 100

as_tibble(state_pres_approval) # Check to see if it worked. Clearly it did!

approval_2016 <- subset(state_pres_approval,state_pres_approval$year == 2016) # Subet our data

# Let's merge our data onto the map!

approval_2016 <- subset(approval_2016,select=c("state","state_pres_approval_percent"))

state_shp@data$id <- rownames(state_shp@data)
state_shp.points <- fortify(state_shp, region="id")

state_shp.df <- join(state_shp.points, state_shp@data, by="id")
state_shp.df$state <- as.character(state_shp.df$STUSPS)

state_shp.df <- merge(state_shp.df,approval_2016,by=c("state"))

ggplot(state_shp.df, aes(x = long, y = lat, group = group,fill=state_pres_approval_percent),color="white") + geom_polygon(color = "black") + theme_void() + scale_fill_gradient("Presidential Approval",low = 'red', high = 'blue') + ggtitle("Presidential Approval in the U.S. States, 2016")  + coord_equal() + coord_fixed(1.3)
```

As one can see, we have some pretty good face validity with our MRP estimates. First, President Obama is popular where you would expect him to be in states such as California, New York, and Vermont. Moreover, he is chronically unpopular where you would expect him to be, in states such as West Virginia and Idaho.
  
We can also use R to create social network graphs. In the following example, we will visualize the cosponsorship network on programmatic issues in the 113th United States Senate. Let's explore our data.

```{r echo=F, message=F, warning=FALSE}
library(network)
library(igraph)
library(ggnet)

idmaker = function(vec){
  return(paste(sort(vec), collapse=""))
}

senate <- read.csv(paste("/Users/carlosalgara/Desktop/carlos_school/PhD_UC Davis/Research/Submissions & Applications/Pol_Net_2018/Raw_Network_Legislator_attributes_Data/U.S. Senate/","senate_programmatic_particularistic_",113,"congress_network.csv",sep=""),stringsAsFactors=FALSE, na.strings=c(""," ","NA"))
senate$X <- NULL
co_id <- apply(as.matrix(senate[, c("NameFull_senator_j", "NameFull_senator_i")]), 1, idmaker)
senate <- cbind(senate, co_id)
senate <- senate[!duplicated(senate[,"co_id"]),]
senate_networks <- senate

x <- senate_networks
x$edge <- ifelse(x$number_cosponsored_bills_particularistic >= mean(x$number_cosponsored_bills_particularistic,na.rm=T),1,ifelse(x$number_cosponsored_bills_particularistic < mean(x$number_cosponsored_bills_particularistic,na.rm=T),0,NA))
x <- na.omit(x)
```

```{r echo=T, message=F, warning=FALSE}
library(network)
library(igraph)
library(ggnet)

as_tibble(x) # This network data is in dyadic form, where each row indicates a pair of Senators.

adj <- graph.data.frame(x[,c(8,21,43)],directed=T) # Let's create a network object! What we want to extract is a dataframe where the first column is Senator i, the second column is Senator J, and the last column is a binary variable indicating
adj <- get.adjacency(adj,attr='edge',sparse=FALSE) # Convert the edge list to an adjacency matrix
x_ergm <- network(adj, matrix.type = "adjacency", ignore.eval = FALSE,directed = F,weighted = F,names.eval="edge") # Convert the adjacency matrix to a network object

# Now let's create some attributes and load them on the network object!

y <- x[,c(8,10,2)]
y1 <- x[,c(21,23,1)]
colnames(y) <- c("NameFull_senator","Party_senator","State_senator")
colnames(y1) <- c("NameFull_senator","Party_senator","State_senator")
party <- rbind(y,y1)
rm(y,y1)
party$Party_senator <- ifelse(party$Party_senator == 200, "R",ifelse(party$Party_senator == 100, "D",NA))
party <- data.table(party)
party <-  party[, duplicates := 1:.N , by = c("NameFull_senator")]
party <- subset(party,party$duplicates == 1)
party <- data.frame(party)
party$duplicates <- NULL
network.vertex.names(x_ergm)
x_ergm%v%'party'<- party$Party_senator # Merge the party attributes for each Senator!
x_ergm%v%'state'<- party$State_senator # Merge the state attributes for each Senator!
x_ergm%v%"color" = ifelse(x_ergm%v%"party" == "R", "red", "blue") # Create color indicators!
```

Now, let's create three network graphs using various labels for our nodes!
```{r echo=T, message=F, warning=FALSE}
ggnet2(x_ergm, label = "state", color = "grey15", label.color = "color",alpha = 0, size = 0, edge.alpha = 0.5,mode = "kamadakawai",label.size = 3) + ggtitle("113th U.S. Senate Particularistic Cosponsorship Network")

ggnet2(x_ergm, label = "vertex.names", color = "grey15", label.color = "color",alpha = 0, size = 0, edge.alpha = 0.5,mode = "kamadakawai",label.size = 3) + ggtitle("113th U.S. Senate Particularistic Cosponsorship Network")

ggnet2(x_ergm, color = "color", alpha = 0.75, size = 4, edge.alpha = 0.5,vjust = -0.6,mode = "kamadakawai") + ggtitle("113th U.S. Senate Particularistic Cosponsorship Network")
```